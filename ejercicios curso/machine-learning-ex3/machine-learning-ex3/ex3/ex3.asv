%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all

%  Instructions
%  ------------
%
%  This file contains code that helps you get started on the
%  linear exercise. You will need to complete the following functions
%  in this exericse:
%
%     lrCostFunction.m (logistic regression cost function)
%     oneVsAll.m
%     predictOneVsAll.m
%     predict.m
%
%  For this exercise, you will not need to change any code in this file,
%  or any other files other than those mentioned above.
%

%% Initialization
clear ; close all; clc

%% Setup the parameters you will use for this part of the exercise
input_layer_size  = 400;  % 20x20 Input Images of Digits
num_labels = 10;          % 10 etiquetas desde 1 a 10
                          % siendo el 10 en verdad el numero 0
                   

%% =========== Part 1: Loading and Visualizing Data =============
%  carga el set de datos de las imagenes de los digitos escritos

fprintf('cargando ...\n')

% .mat carga la matriz que tiene los x y los y
load('ex3data1.mat'); 


m = size(X, 1); %tambien podria haber sido asi
% m = length(y);

% selecciona al azar 100 puntos para mostrar
% m es 5000 que son la cantidad de datos que tengo
% retorna un vector con numeros aleatorios desde 1 a m
rand_indices = randperm(m);

% de esos 5000 aleatorios agarra los primeros 100 registros y guarda las
% 400 variables
sel = X(rand_indices(1:100), :);

% muestra los datos
displayData(sel);

fprintf('Program paused. Press enter to continue.\n');
pause;

%% ============ Part 2a: Vectorize Logistic Regression ============
% en esta parte del ejercicio, deberas reusar el codigo de regresion logistica
% del ultimo ejercicio. la tarea aqui es asegurarse que la implementacion
% de la regresion logistica regularizada esta vectorizada.
% despues de eso, se debera implementar la clasificacion uno contra todos
% para el set de datos de los digitos escritos a mano

fprintf('\nTesteando lrCostFunction() con regularizacion');

% setea theta inicial
theta_t = [-2; -1; 1; 2];
% la primer columna como siempre es de 1,
% convierte los numeros del 1 al 15 en un vector 5x3 y divide cada
% miembro por 10,supongo que para normalizar
X_t = [ones(5,1), reshape(1:15,[5,3])/10];

% evalua si cada termino es mayor a 0.5 y setea el vector y_t en base a eso
% si es mayor setea 1 sino 0. aca le puse 2 al primero para que se vea que funciona
% igual
y_t = ([2;0;1;0;1] >= 0.5);

% setea un lambda de 3
lambda_t = 3;

% llama a la funcion costo de regresion logistica regularizada
% devuelve el costo y el gradiente
[J grad] = lrCostFunction(theta_t, X_t, y_t, lambda_t);

fprintf('\nCosto calculado: %f\n', J);
fprintf('costo esperado: 2.534819\n');

fprintf('Gradientes calculados:\n');
fprintf(' %f \n', grad);
fprintf('gradientes esperados:\n');
fprintf(' 0.146561\n -0.548558\n 0.724722\n 1.398003\n');

fprintf('Program paused. Press enter to continue.\n');
pause;
%% ============ Part 2b: One-vs-All Training ============
fprintf('\nEntrenando regresion logistica de uno contra todos (ONE-VS-ALL)...\n')

% setea un lambda de 0.1
lambda = 0.1;

% llama a uno contra todos
[all_theta] = oneVsAll(X, y, num_labels, lambda);

fprintf('Program paused. Press enter to continue.\n');
pause;


%% ================ Part 3: Predict for One-Vs-All ================

% predice con el theta encontrado y guarda los resultados
pred = predictOneVsAll(all_theta, X);

valor = imread('1.bmp');
valor = [ones(400m10valor(:);
 pred2= predictOneVsAll(all_theta, valor);
% fprintf('%d',valor);
% calcula el porcentaje total de aciertos
fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100);

